{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section goes on to read the input data and study how they are made, check the dataset size, add the necessary labels to classify, truncate the useless columns and merge the two datasets provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to read the data from a CSV file and print some information about it\n",
    "def read_data(file_path):\n",
    "    print(\"Opening dataset:\", file_path)\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataframe shape:\", df.shape)\n",
    "    print(\"Dataframe columns:\", df.columns)\n",
    "    print(\"Number of missing values in each column:\\n\", df.isnull().sum(), \"\\n\")\n",
    "    print(\"Removing duplicates in the dataset:\", df.duplicated().sum(), \"\\n\")\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "# Open CSV files\n",
    "true_data = read_data(\"Datasets/True.csv\") # True news\n",
    "true_data['label'] = 1 # Add a label column to the true data\n",
    "\n",
    "false_data = read_data(\"Datasets/Fake.csv\") # Fake news\n",
    "false_data['label'] = 0 # Add a label column to the fake data\n",
    "\n",
    "# We actually don't need the date column for the classification\n",
    "true_data.drop(columns=['date'])\n",
    "false_data.drop(columns=['date'])\n",
    "\n",
    "# Merge the two datasets\n",
    "dataset = pd.concat([true_data, false_data], ignore_index=True) # Ignore index to reset the index\n",
    "print(\"Dataset merged, resulting shape:\", dataset.shape)\n",
    "\n",
    "# Check if the dataset has the correct shape\n",
    "assert dataset.shape[0] == true_data.shape[0] + false_data.shape[0]\n",
    "assert dataset.shape[1] == true_data.shape[1] == false_data.shape[1]\n",
    "assert dataset.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Create a new label that has title and text\n",
    "dataset['full_text'] = dataset['title'] + \" \" + dataset['text']\n",
    "\n",
    "# Remove the title and text columns\n",
    "dataset = dataset.drop(columns=['title', 'text', 'date', 'subject'])\n",
    "\n",
    "# Download the stopwords from NLTK if not already downloaded\n",
    "if not nltk.data.find('corpora/stopwords'):\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# Inspired by : https://www.analyticsvidhya.com/blog/2022/01/text-cleaning-methods-in-nlp/\n",
    "def text_cleaner(text):\n",
    "    # Lowercasing the data\n",
    "    text = text.lower()\n",
    "\n",
    "    # Removing Puncuatations\n",
    "    punctuations = string.punctuation\n",
    "    text = ''.join([char for char in text if char not in punctuations])\n",
    "\n",
    "    # Removing Numbers\n",
    "    # Actually, we can keep the numbers as they can be useful in the classification\n",
    "    # By the way, the code for remove them is:\n",
    "    # text = re.sub('[0-9]+', '', text)\n",
    "\n",
    "    # Removing extra space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    # Replacing the repetitions of punctations\n",
    "    text = re.sub(r'([!?,.])\\1+', r'\\1', text)\n",
    "\n",
    "    # Removing Emojis\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    # Removing emoticons\n",
    "    text = re.sub(':\\)|;\\)|:-\\)|\\(-:|:-D|=D|:P|xD|X-p|\\^\\^|:-*|\\^\\.\\^|\\^\\-\\^|\\^\\_\\^|\\,-\\)|\\)-:|:\\'\\(|:\\(|:-\\(|:\\S|T\\.T|\\.\\_\\.|:<|:-\\S|:-<|\\*\\-\\*|:O|=O|=\\-O|O\\.o|XO|O\\_O|:-\\@|=/|:/|X\\-\\(|>\\.<|>=\\(|D:', '', text)\n",
    "\n",
    "    # Removing Contractions\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    # Removing URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Removing stopwords\n",
    "    # We can use the stopwords from NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "    return text\n",
    "\n",
    "# Clean the text\n",
    "dataset['full_text'] = dataset['full_text'].apply(text_cleaner)\n",
    "\n",
    "# Save the dataset\n",
    "dataset.to_csv(\"Datasets/News.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved to 'Datasets/News.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section goes on to split the data into training and testing data using the according functions from sklearn. The TfidfVectorizer is then used to convert the text data into numerical data that can be used for the classification, using the fit_transform function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test train data split and import TfidfVectorizer to implement Bag of Words\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the dataset into training and testing data\n",
    "X_train,X_test,y_train,y_test=train_test_split(dataset.full_text,dataset.label,test_size=.2,random_state=1)\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "\n",
    "# Initialize the TfidfVectorizer, which will convert the text data into a matrix of token counts\n",
    "# We can also use CountVectorizer, but TfidfVectorizer is more efficient because it considers the frequency of the words\n",
    "cv=TfidfVectorizer()\n",
    "\n",
    "# Fitting the classifier to the training data\n",
    "x_train_cv = cv.fit_transform(X_train)\n",
    "x_test_cv = cv.transform(X_test)\n",
    "predictions_list = [] # List to store the future predictions\n",
    "classifier_name_list = [] # List to store the classifier names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few sections will use various Classifier to predict the test values that have been splitted from the dataset. They are predicted using the TfidfVectorizer that have been fitted to the training data. Then the predictions are appended to a list to be used for plotting various analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(x_train_cv,y_train)\n",
    "y_pred_randomForest=rf.predict(x_test_cv)\n",
    "\n",
    "predictions_list.append(y_pred_randomForest)\n",
    "classifier_name_list.append(\"Random Forest Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train_cv,y_train)\n",
    "y_pred_knn=knn.predict(x_test_cv)\n",
    "\n",
    "predictions_list.append(y_pred_knn)\n",
    "classifier_name_list.append(\"KNN Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train_cv, y_train)\n",
    "y_pred_log_reg = log_reg.predict(x_test_cv)\n",
    "\n",
    "predictions_list.append(y_pred_log_reg)\n",
    "classifier_name_list.append(\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Support Vector Machine\n",
    "#from sklearn.svm import SVC\n",
    "\n",
    "#supvm  = SVC()\n",
    "#supvm.fit(x_train_cv, y_train)\n",
    "#y_pred_supvm = supvm.predict(x_test_cv)\n",
    "\n",
    "#predictions_list.append(y_pred_supvm)\n",
    "#classifier_name_list.append(\"Support Vector Machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Multinomial Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train_cv, y_train)\n",
    "y_pred_mnb = mnb.predict(x_test_cv)\n",
    "\n",
    "predictions_list.append(y_pred_mnb)\n",
    "classifier_name_list.append(\"Multinomial Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section implements plotting and classification report for each classifier that was used in the predictions_list, which contains the predictions for each classifier using the test data set. The classification report shows the precision, recall, f1-score and support for each class. The accuracy is also shown. The confusion matrix shows the true positive, false positive, true negative and false negative values. The ROC curve shows the true positive rate against the false positive rate. The AUC (Area Under the Curve) is also shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy of the model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "\n",
    "# Function to plot the accuracy of the model\n",
    "def plot_accuracy(y_test,y_pred):\n",
    "    print(accuracy_score(y_test,y_pred))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.pie([accuracy_score(y_test,y_pred),1-accuracy_score(y_test,y_pred)],labels=['Accuracy','Error'],autopct='%1.3f%%')\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot the confusion matrix\n",
    "def plot_confusion_matrix(y_test,y_pred):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    sns.heatmap(cm,annot=True,fmt='d')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot the ROC AUC curve\n",
    "def plot_roc_auc_curve(y_test, y_pred, classifier_name):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred) # Calculate the FPR and TPR\n",
    "    auc = roc_auc_score(y_test, y_pred) # Calculate the AUC\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.2f})')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - ' + classifier_name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Print the classification report and plot the accuracy, \n",
    "# confusion matrix and ROC AUC curve and learning curve for each classifier\n",
    "for index, y_pred in enumerate(predictions_list):\n",
    "    print(\"Now showing results for\",classifier_name_list[index])\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    plot_accuracy(y_test, y_pred)\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "    plot_roc_auc_curve(y_test, y_pred, classifier_name_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot learning curves\n",
    "def plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "for index, y_pred in enumerate(predictions_list):\n",
    "    plot_learning_curve(rf, classifier_name_list[index], x_train_cv, y_train, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading external articles to test the model\n",
    "\n",
    "def load_articles(file_path):\n",
    "    articles = []\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as file:\n",
    "        for line in file:\n",
    "            articles.append(line)\n",
    "    return articles\n",
    "\n",
    "#In this dataset, the articles with an even index are true, the ones with an odd index are fake\n",
    "\n",
    "articles = load_articles(\"externalArticles.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input a news article to test the model\n",
    "\n",
    "def test_news_input(text, classifier):\n",
    "    news_cv = cv.transform([text])\n",
    "    return classifier.predict(news_cv)\n",
    "\n",
    "predicted_label = test_news_input(articles[3], knn)\n",
    "print(\"The news article is: \", \"True\" if predicted_label else \"Fake\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
