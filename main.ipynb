{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section goes on to read the input data and study how they are made, check the dataset size, add the necessary labels to classify, truncate the useless columns and merge the two datasets provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to read the data from a CSV file and print some information about it\n",
    "def read_data(file_path):\n",
    "    print(\"Opening dataset:\", file_path)\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataframe shape:\", df.shape)\n",
    "    print(\"Dataframe columns:\", df.columns)\n",
    "    print(\"Number of missing values in each column:\\n\", df.isnull().sum(), \"\\n\")\n",
    "    return df\n",
    "\n",
    "# Open CSV files\n",
    "true_data = read_data(\"Datasets/True.csv\") # True news\n",
    "true_data['label'] = 1 # Add a label column to the true data\n",
    "\n",
    "false_data = read_data(\"Datasets/Fake.csv\") # Fake news\n",
    "false_data['label'] = 0 # Add a label column to the fake data\n",
    "\n",
    "# We actually don't need the date column for the classification\n",
    "true_data.drop(columns=['date'])\n",
    "false_data.drop(columns=['date'])\n",
    "\n",
    "# Merge the two datasets\n",
    "dataset = pd.concat([true_data, false_data], ignore_index=True) # Ignore index to reset the index\n",
    "print(\"Dataset merged, resulting shape:\", dataset.shape)\n",
    "\n",
    "# Check if the dataset has the correct shape\n",
    "assert dataset.shape[0] == true_data.shape[0] + false_data.shape[0]\n",
    "assert dataset.shape[1] == true_data.shape[1] == false_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section goes on to split the data into training and testing data using the according functions from sklearn. The CountVectorizer is then used to convert the text data into numerical data that can be used for the classification, using the fit_transform function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test train data split and import CountVectorizer to implement Bag of Words\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Split the dataset into training and testing data\n",
    "X_train,X_test,y_train,y_test=train_test_split(dataset.text,dataset.label,test_size=.2,random_state=1)\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "\n",
    "# Initialize the CountVectorizer, which will convert the text data into a matrix of token counts\n",
    "cv=CountVectorizer()\n",
    "\n",
    "# Fitting the classifier to the training data\n",
    "x_train_cv = cv.fit_transform(X_train)\n",
    "x_test_cv = cv.transform(X_test)\n",
    "predictions_list = [] # List to store the future predictions\n",
    "classifier_name_list = [] # List to store the classifier names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few sections will use various Classifier to predict the test values that have been splitted from the dataset. They are predicted using the CountVectorizer that have been fitted to the training data. Then the predictions are appended to a list to be used for plotting various analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(x_train_cv,y_train)\n",
    "y_pred_randomForest=rf.predict(x_test_cv)\n",
    "\n",
    "predictions_list.append(y_pred_randomForest)\n",
    "classifier_name_list.append(\"Random Forest Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train_cv,y_train)\n",
    "y_pred_knn=knn.predict(x_test_cv)\n",
    "\n",
    "predictions_list.append(y_pred_knn)\n",
    "classifier_name_list.append(\"KNN Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train_cv, y_train)\n",
    "y_pred_log_reg = log_reg.predict(x_test_cv)\n",
    "\n",
    "predictions_list.append(y_pred_log_reg)\n",
    "classifier_name_list.append(\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "supvm  = SVC()\n",
    "# supvm.fit(x_train_cv, y_train)\n",
    "# y_pred_supvm = supvm.predict(x_test_cv)\n",
    "\n",
    "# predictions_list.append(y_pred_supvm)\n",
    "# classifier_name_list.append(\"Support Vector Machine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section implements plotting and classification report for each classifier that was used in the predictions_list, which contains the predictions for each classifier using the test data set. The classification report shows the precision, recall, f1-score and support for each class. The accuracy is also shown. The confusion matrix shows the true positive, false positive, true negative and false negative values. The ROC curve shows the true positive rate against the false positive rate. The AUC (Area Under the Curve) is also shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy of the model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "\n",
    "# Function to plot the accuracy of the model\n",
    "def plot_accuracy(y_test,y_pred):\n",
    "    print(accuracy_score(y_test,y_pred))\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.pie([accuracy_score(y_test,y_pred),1-accuracy_score(y_test,y_pred)],labels=['Accuracy','Error'],autopct='%1.3f%%')\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot the confusion matrix\n",
    "def plot_confusion_matrix(y_test,y_pred):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    sns.heatmap(cm,annot=True,fmt='d')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot the ROC AUC curve\n",
    "def plot_roc_auc_curve(y_test, y_pred, classifier_name):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred) # Calculate the FPR and TPR\n",
    "    auc = roc_auc_score(y_test, y_pred) # Calculate the AUC\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.2f})')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - ' + classifier_name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Print the classification report and plot the accuracy, \n",
    "# confusion matrix and ROC AUC curve for each classifier\n",
    "for index, y_pred in enumerate(predictions_list):\n",
    "    print(\"Now showing results for\",classifier_name_list[index])\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    plot_accuracy(y_test, y_pred)\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "    plot_roc_auc_curve(y_test, y_pred, classifier_name_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input a news article to test the model\n",
    "\n",
    "def test_news_input(text, classifier):\n",
    "    news_cv = cv.transform([text])\n",
    "    return classifier.predict(news_cv)\n",
    "\n",
    "predicted_label = test_news_input(\"Donald Trump\", rf)\n",
    "print(\"The news article is: \", \"True\" if predicted_label else \"Fake\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
